{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cgX3M3Vy1V-9"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import imutils\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "# from keras.applications.resnet50 import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 600071,
     "status": "ok",
     "timestamp": 1586437407820,
     "user": {
      "displayName": "Son Nguyen Trung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIjDYO028a7pzOM7YCOrcF0wUZoyGg-WZY7mtZ=s64",
      "userId": "15431692547784691678"
     },
     "user_tz": -420
    },
    "id": "KMqIl4E32b-w",
    "outputId": "a497a78a-3f53-4b60-d2c4-8c3991849361"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [24:54<00:00,  2.21it/s]\n",
      "100%|██████████| 2200/2200 [15:33<00:00,  2.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3300, 224, 224, 1), (3300,))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_labels(file):\n",
    "    with open(file,'r') as f:\n",
    "        lines = f.readlines()\n",
    "        return np.array([line.strip().split() for line in lines])\n",
    "    \n",
    "def index_process(flo):\n",
    "    below = math.floor(flo)\n",
    "    top = math.ceil(flo)\n",
    "    \n",
    "    result = np.zeros(5)\n",
    "    result[below-1] = top-round(flo)\n",
    "    result[top-1] = round(flo)-below\n",
    "    \n",
    "    return result\n",
    "\n",
    "#loading of images and labels\n",
    "#Cross validation was made by the dataset provider\n",
    "TRAIN_TEST_PATH = './train_test_files/'\n",
    "train_labels = get_labels(TRAIN_TEST_PATH+'train.txt')\n",
    "test_labels = get_labels(TRAIN_TEST_PATH+'test.txt')\n",
    "\n",
    "PATH_IMAGES = './Images/'\n",
    "X_pre_train = [cv2.imread(PATH_IMAGES+file,0) for file in tqdm(train_labels[:,0])]\n",
    "X_train = np.array([cv2.resize(img,(224,224),interpolation=cv2.INTER_AREA) for img in X_pre_train])\n",
    "\n",
    "X_pre_test = [cv2.imread(PATH_IMAGES+file,0) for file in tqdm(test_labels[:,0])]\n",
    "X_test = np.array([cv2.resize(img,(224,224),interpolation=cv2.INTER_AREA) for img in X_pre_test])\n",
    "\n",
    "y_train = np.array([float(flo) for flo in train_labels[:,1]])\n",
    "y_test = np.array([float(flo) for flo in test_labels[:,1]])\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],X_train.shape[2],1))\n",
    "X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],X_test.shape[2],1))\n",
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMfpFIXYLmEQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cKKcNd32s4i"
   },
   "outputs": [],
   "source": [
    "# def euclidean_distance_loss(y_true, y_pred):\n",
    "#     \"\"\"\n",
    "#     Euclidean distance loss\n",
    "#     https://en.wikipedia.org/wiki/Euclidean_distance\n",
    "#     :param y_true: TensorFlow/Theano tensor\n",
    "#     :param y_pred: TensorFlow/Theano tensor of the same shape as y_true\n",
    "#     :return: float\n",
    "#     \"\"\"\n",
    "#     return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0F-naZpxCGZP"
   },
   "outputs": [],
   "source": [
    "# resnet = ResNet50(include_top=False, pooling='avg', input_shape=((224,224,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9hpNAd7CKYz"
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(resnet)\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(5, activation='softmax'))\n",
    "# model.layers[0].trainable = False\n",
    "# print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wzt4XJB9UMuy"
   },
   "outputs": [],
   "source": [
    "class Beau:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.model = Sequential()\n",
    "\n",
    "        #1st 2dConvolutional Layer\n",
    "        self.model.add(Conv2D(64, (3, 3), padding='same', input_shape=(224, 224, 1)))\n",
    "        self.model.add(Activation('relu'))\n",
    "\n",
    "        #1st 2dMaxPool Layer\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(0.5))\n",
    "\n",
    "        #2nd 2dConvolutional Layer\n",
    "        self.model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "        self.model.add(Activation('relu'))\n",
    "\n",
    "        #2nd 2dMaxPool Layer\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(0.25))\n",
    "\n",
    "        #3rd 2dConvolutional Layer\n",
    "        self.model.add(Conv2D(128, (5, 5), padding='same'))\n",
    "        self.model.add(Activation('relu'))\n",
    "\n",
    "        #3rd 2dMaxPool Layer\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(0.5))\n",
    "        \n",
    "        #4th 2dConvolutional Layer\n",
    "        self.model.add(Conv2D(128, (5, 5), padding='same'))\n",
    "        self.model.add(Activation('relu'))\n",
    "\n",
    "        #3rd 2dMaxPool Layer\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(0.25))\n",
    "        \n",
    "        #5th 2dConvolutional Layer\n",
    "        self.model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(BatchNormalization())\n",
    "\n",
    "        #3rd 2dMaxPool Layer\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(0.25))\n",
    "        \n",
    "        #6th 2dConvolutional Layer\n",
    "        self.model.add(Conv2D(512, (5, 5), padding='same'))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(BatchNormalization())\n",
    "\n",
    "        self.model.add(MaxPooling2D(pool_size=(1, 1)))  \n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(0.5))\n",
    "\n",
    "        self.model.add(Conv2D(1024, (5, 5), padding='same'))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(BatchNormalization())\n",
    "\n",
    "        self.model.add(Flatten())\n",
    "\n",
    "        #1st FC Layer\n",
    "        self.model.add(Dense(256))\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Dropout(0.25))\n",
    "        \n",
    "        #2nd FC Layer\n",
    "        self.model.add(Dense(512))\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Dropout(0.25))\n",
    "\n",
    "        # Output layer\n",
    "        self.model.add(Dense(1))\n",
    "        self.model.add(Activation('relu'))\n",
    "\n",
    "        # self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1586438061146,
     "user": {
      "displayName": "Son Nguyen Trung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIjDYO028a7pzOM7YCOrcF0wUZoyGg-WZY7mtZ=s64",
      "userId": "15431692547784691678"
     },
     "user_tz": -420
    },
    "id": "Qo5Oe6O4VW_P",
    "outputId": "fe0449b4-b4ce-498f-e77a-ea0d17ee8af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      640       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 1024)        13108224  \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               12845312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 30,325,185\n",
      "Trainable params: 30,317,761\n",
      "Non-trainable params: 7,424\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Beau().model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1162538,
     "status": "ok",
     "timestamp": 1586440453508,
     "user": {
      "displayName": "Son Nguyen Trung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIjDYO028a7pzOM7YCOrcF0wUZoyGg-WZY7mtZ=s64",
      "userId": "15431692547784691678"
     },
     "user_tz": -420
    },
    "id": "kokzOO3JCXtJ",
    "outputId": "ca987f43-089b-405f-9703-f16827413930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4975 - root_mean_squared_error: 0.4972\n",
      "Epoch 00001: val_loss improved from inf to 0.57123, saving model to 01-0.57.h5\n",
      "26/26 [==============================] - 19s 738ms/step - loss: 0.4975 - root_mean_squared_error: 0.4972 - val_loss: 0.5712 - val_root_mean_squared_error: 0.5761\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4908 - root_mean_squared_error: 0.4912\n",
      "Epoch 00002: val_loss improved from 0.57123 to 0.56050, saving model to 02-0.56.h5\n",
      "26/26 [==============================] - 19s 729ms/step - loss: 0.4908 - root_mean_squared_error: 0.4912 - val_loss: 0.5605 - val_root_mean_squared_error: 0.5651\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4737 - root_mean_squared_error: 0.4744\n",
      "Epoch 00003: val_loss improved from 0.56050 to 0.55987, saving model to 03-0.56.h5\n",
      "26/26 [==============================] - 19s 732ms/step - loss: 0.4737 - root_mean_squared_error: 0.4744 - val_loss: 0.5599 - val_root_mean_squared_error: 0.5646\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4827 - root_mean_squared_error: 0.4832\n",
      "Epoch 00004: val_loss improved from 0.55987 to 0.54511, saving model to 04-0.55.h5\n",
      "26/26 [==============================] - 19s 734ms/step - loss: 0.4827 - root_mean_squared_error: 0.4832 - val_loss: 0.5451 - val_root_mean_squared_error: 0.5496\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4880 - root_mean_squared_error: 0.4876\n",
      "Epoch 00005: val_loss improved from 0.54511 to 0.54145, saving model to 05-0.54.h5\n",
      "26/26 [==============================] - 19s 734ms/step - loss: 0.4880 - root_mean_squared_error: 0.4876 - val_loss: 0.5414 - val_root_mean_squared_error: 0.5459\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4824 - root_mean_squared_error: 0.4828\n",
      "Epoch 00006: val_loss improved from 0.54145 to 0.53012, saving model to 06-0.53.h5\n",
      "26/26 [==============================] - 19s 734ms/step - loss: 0.4824 - root_mean_squared_error: 0.4828 - val_loss: 0.5301 - val_root_mean_squared_error: 0.5346\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4783 - root_mean_squared_error: 0.4781\n",
      "Epoch 00007: val_loss improved from 0.53012 to 0.52148, saving model to 07-0.52.h5\n",
      "26/26 [==============================] - 19s 732ms/step - loss: 0.4783 - root_mean_squared_error: 0.4781 - val_loss: 0.5215 - val_root_mean_squared_error: 0.5260\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4847 - root_mean_squared_error: 0.4846\n",
      "Epoch 00008: val_loss did not improve from 0.52148\n",
      "26/26 [==============================] - 18s 711ms/step - loss: 0.4847 - root_mean_squared_error: 0.4846 - val_loss: 0.5256 - val_root_mean_squared_error: 0.5301\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4801 - root_mean_squared_error: 0.4796\n",
      "Epoch 00009: val_loss improved from 0.52148 to 0.51898, saving model to 09-0.52.h5\n",
      "26/26 [==============================] - 19s 733ms/step - loss: 0.4801 - root_mean_squared_error: 0.4796 - val_loss: 0.5190 - val_root_mean_squared_error: 0.5234\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4852 - root_mean_squared_error: 0.4849\n",
      "Epoch 00010: val_loss improved from 0.51898 to 0.51796, saving model to 10-0.52.h5\n",
      "26/26 [==============================] - 19s 732ms/step - loss: 0.4852 - root_mean_squared_error: 0.4849 - val_loss: 0.5180 - val_root_mean_squared_error: 0.5224\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4722 - root_mean_squared_error: 0.4721\n",
      "Epoch 00011: val_loss did not improve from 0.51796\n",
      "26/26 [==============================] - 18s 711ms/step - loss: 0.4722 - root_mean_squared_error: 0.4721 - val_loss: 0.5257 - val_root_mean_squared_error: 0.5302\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4793 - root_mean_squared_error: 0.4793\n",
      "Epoch 00012: val_loss did not improve from 0.51796\n",
      "26/26 [==============================] - 18s 711ms/step - loss: 0.4793 - root_mean_squared_error: 0.4793 - val_loss: 0.5200 - val_root_mean_squared_error: 0.5245\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4715 - root_mean_squared_error: 0.4725\n",
      "Epoch 00013: val_loss improved from 0.51796 to 0.51379, saving model to 13-0.51.h5\n",
      "26/26 [==============================] - 19s 730ms/step - loss: 0.4715 - root_mean_squared_error: 0.4725 - val_loss: 0.5138 - val_root_mean_squared_error: 0.5180\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4829 - root_mean_squared_error: 0.4828\n",
      "Epoch 00014: val_loss improved from 0.51379 to 0.51066, saving model to 14-0.51.h5\n",
      "26/26 [==============================] - 19s 731ms/step - loss: 0.4829 - root_mean_squared_error: 0.4828 - val_loss: 0.5107 - val_root_mean_squared_error: 0.5148\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4761 - root_mean_squared_error: 0.4763\n",
      "Epoch 00015: val_loss did not improve from 0.51066\n",
      "26/26 [==============================] - 18s 710ms/step - loss: 0.4761 - root_mean_squared_error: 0.4763 - val_loss: 0.5139 - val_root_mean_squared_error: 0.5183\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4831 - root_mean_squared_error: 0.4834\n",
      "Epoch 00016: val_loss did not improve from 0.51066\n",
      "26/26 [==============================] - 18s 709ms/step - loss: 0.4831 - root_mean_squared_error: 0.4834 - val_loss: 0.5116 - val_root_mean_squared_error: 0.5160\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4844 - root_mean_squared_error: 0.4843\n",
      "Epoch 00017: val_loss improved from 0.51066 to 0.50480, saving model to 17-0.50.h5\n",
      "26/26 [==============================] - 19s 734ms/step - loss: 0.4844 - root_mean_squared_error: 0.4843 - val_loss: 0.5048 - val_root_mean_squared_error: 0.5091\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4654 - root_mean_squared_error: 0.4654\n",
      "Epoch 00018: val_loss improved from 0.50480 to 0.50333, saving model to 18-0.50.h5\n",
      "26/26 [==============================] - 19s 735ms/step - loss: 0.4654 - root_mean_squared_error: 0.4654 - val_loss: 0.5033 - val_root_mean_squared_error: 0.5075\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4761 - root_mean_squared_error: 0.4759\n",
      "Epoch 00019: val_loss did not improve from 0.50333\n",
      "26/26 [==============================] - 19s 712ms/step - loss: 0.4761 - root_mean_squared_error: 0.4759 - val_loss: 0.5052 - val_root_mean_squared_error: 0.5093\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4799 - root_mean_squared_error: 0.4797\n",
      "Epoch 00020: val_loss improved from 0.50333 to 0.50148, saving model to 20-0.50.h5\n",
      "26/26 [==============================] - 19s 735ms/step - loss: 0.4799 - root_mean_squared_error: 0.4797 - val_loss: 0.5015 - val_root_mean_squared_error: 0.5056\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4792 - root_mean_squared_error: 0.4788\n",
      "Epoch 00021: val_loss did not improve from 0.50148\n",
      "26/26 [==============================] - 18s 710ms/step - loss: 0.4792 - root_mean_squared_error: 0.4788 - val_loss: 0.5029 - val_root_mean_squared_error: 0.5072\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4651 - root_mean_squared_error: 0.4651\n",
      "Epoch 00022: val_loss did not improve from 0.50148\n",
      "26/26 [==============================] - 18s 710ms/step - loss: 0.4651 - root_mean_squared_error: 0.4651 - val_loss: 0.5062 - val_root_mean_squared_error: 0.5107\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4682 - root_mean_squared_error: 0.4680\n",
      "Epoch 00023: val_loss improved from 0.50148 to 0.50073, saving model to 23-0.50.h5\n",
      "26/26 [==============================] - 19s 731ms/step - loss: 0.4682 - root_mean_squared_error: 0.4680 - val_loss: 0.5007 - val_root_mean_squared_error: 0.5049\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4628 - root_mean_squared_error: 0.4625\n",
      "Epoch 00024: val_loss did not improve from 0.50073\n",
      "26/26 [==============================] - 18s 708ms/step - loss: 0.4628 - root_mean_squared_error: 0.4625 - val_loss: 0.5025 - val_root_mean_squared_error: 0.5067\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4740 - root_mean_squared_error: 0.4732\n",
      "Epoch 00025: val_loss did not improve from 0.50073\n",
      "26/26 [==============================] - 18s 710ms/step - loss: 0.4740 - root_mean_squared_error: 0.4732 - val_loss: 0.5042 - val_root_mean_squared_error: 0.5084\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4595 - root_mean_squared_error: 0.4595\n",
      "Epoch 00026: val_loss did not improve from 0.50073\n",
      "26/26 [==============================] - 18s 710ms/step - loss: 0.4595 - root_mean_squared_error: 0.4595 - val_loss: 0.5014 - val_root_mean_squared_error: 0.5055\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4593 - root_mean_squared_error: 0.4592\n",
      "Epoch 00027: val_loss improved from 0.50073 to 0.49997, saving model to 27-0.50.h5\n",
      "26/26 [==============================] - 19s 733ms/step - loss: 0.4593 - root_mean_squared_error: 0.4592 - val_loss: 0.5000 - val_root_mean_squared_error: 0.5042\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4627 - root_mean_squared_error: 0.4629\n",
      "Epoch 00028: val_loss did not improve from 0.49997\n",
      "26/26 [==============================] - 18s 709ms/step - loss: 0.4627 - root_mean_squared_error: 0.4629 - val_loss: 0.5031 - val_root_mean_squared_error: 0.5075\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4612 - root_mean_squared_error: 0.4609\n",
      "Epoch 00029: val_loss improved from 0.49997 to 0.49889, saving model to 29-0.50.h5\n",
      "26/26 [==============================] - 19s 731ms/step - loss: 0.4612 - root_mean_squared_error: 0.4609 - val_loss: 0.4989 - val_root_mean_squared_error: 0.5029\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4593 - root_mean_squared_error: 0.4593\n",
      "Epoch 00030: val_loss did not improve from 0.49889\n",
      "26/26 [==============================] - 18s 710ms/step - loss: 0.4593 - root_mean_squared_error: 0.4593 - val_loss: 0.5030 - val_root_mean_squared_error: 0.5072\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4641 - root_mean_squared_error: 0.4640\n",
      "Epoch 00031: val_loss did not improve from 0.49889\n",
      "26/26 [==============================] - 18s 711ms/step - loss: 0.4641 - root_mean_squared_error: 0.4640 - val_loss: 0.5093 - val_root_mean_squared_error: 0.5137\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4600 - root_mean_squared_error: 0.4597\n",
      "Epoch 00032: val_loss did not improve from 0.49889\n",
      "26/26 [==============================] - 18s 709ms/step - loss: 0.4600 - root_mean_squared_error: 0.4597 - val_loss: 0.5022 - val_root_mean_squared_error: 0.5064\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4709 - root_mean_squared_error: 0.4708\n",
      "Epoch 00033: val_loss improved from 0.49889 to 0.49659, saving model to 33-0.50.h5\n",
      "26/26 [==============================] - 19s 732ms/step - loss: 0.4709 - root_mean_squared_error: 0.4708 - val_loss: 0.4966 - val_root_mean_squared_error: 0.5004\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4722 - root_mean_squared_error: 0.4723\n",
      "Epoch 00034: val_loss improved from 0.49659 to 0.49408, saving model to 34-0.49.h5\n",
      "26/26 [==============================] - 19s 732ms/step - loss: 0.4722 - root_mean_squared_error: 0.4723 - val_loss: 0.4941 - val_root_mean_squared_error: 0.4977\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4704 - root_mean_squared_error: 0.4707\n",
      "Epoch 00035: val_loss improved from 0.49408 to 0.49407, saving model to 35-0.49.h5\n",
      "26/26 [==============================] - 19s 734ms/step - loss: 0.4704 - root_mean_squared_error: 0.4707 - val_loss: 0.4941 - val_root_mean_squared_error: 0.4977\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4602 - root_mean_squared_error: 0.4606\n",
      "Epoch 00036: val_loss did not improve from 0.49407\n",
      "26/26 [==============================] - 18s 709ms/step - loss: 0.4602 - root_mean_squared_error: 0.4606 - val_loss: 0.4969 - val_root_mean_squared_error: 0.5008\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4643 - root_mean_squared_error: 0.4640\n",
      "Epoch 00037: val_loss did not improve from 0.49407\n",
      "26/26 [==============================] - 18s 709ms/step - loss: 0.4643 - root_mean_squared_error: 0.4640 - val_loss: 0.4988 - val_root_mean_squared_error: 0.5031\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4520 - root_mean_squared_error: 0.4523\n",
      "Epoch 00038: val_loss did not improve from 0.49407\n",
      "26/26 [==============================] - 18s 709ms/step - loss: 0.4520 - root_mean_squared_error: 0.4523 - val_loss: 0.4982 - val_root_mean_squared_error: 0.5022\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4616 - root_mean_squared_error: 0.4615\n",
      "Epoch 00039: val_loss did not improve from 0.49407\n",
      "26/26 [==============================] - 18s 709ms/step - loss: 0.4616 - root_mean_squared_error: 0.4615 - val_loss: 0.4962 - val_root_mean_squared_error: 0.5001\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4608 - root_mean_squared_error: 0.4602\n",
      "Epoch 00040: val_loss improved from 0.49407 to 0.49325, saving model to 40-0.49.h5\n",
      "26/26 [==============================] - 19s 734ms/step - loss: 0.4608 - root_mean_squared_error: 0.4602 - val_loss: 0.4932 - val_root_mean_squared_error: 0.4969\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4623 - root_mean_squared_error: 0.4625\n",
      "Epoch 00041: val_loss improved from 0.49325 to 0.49216, saving model to 41-0.49.h5\n",
      "26/26 [==============================] - 19s 735ms/step - loss: 0.4623 - root_mean_squared_error: 0.4625 - val_loss: 0.4922 - val_root_mean_squared_error: 0.4958\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4668 - root_mean_squared_error: 0.4667\n",
      "Epoch 00042: val_loss did not improve from 0.49216\n",
      "26/26 [==============================] - 18s 710ms/step - loss: 0.4668 - root_mean_squared_error: 0.4667 - val_loss: 0.4932 - val_root_mean_squared_error: 0.4970\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4696 - root_mean_squared_error: 0.4691\n",
      "Epoch 00043: val_loss did not improve from 0.49216\n",
      "26/26 [==============================] - 18s 711ms/step - loss: 0.4696 - root_mean_squared_error: 0.4691 - val_loss: 0.4943 - val_root_mean_squared_error: 0.4984\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4655 - root_mean_squared_error: 0.4647\n",
      "Epoch 00044: val_loss improved from 0.49216 to 0.49075, saving model to 44-0.49.h5\n",
      "26/26 [==============================] - 19s 734ms/step - loss: 0.4655 - root_mean_squared_error: 0.4647 - val_loss: 0.4908 - val_root_mean_squared_error: 0.4946\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4587 - root_mean_squared_error: 0.4593\n",
      "Epoch 00045: val_loss improved from 0.49075 to 0.48939, saving model to 45-0.49.h5\n",
      "26/26 [==============================] - 19s 734ms/step - loss: 0.4587 - root_mean_squared_error: 0.4593 - val_loss: 0.4894 - val_root_mean_squared_error: 0.4935\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4514 - root_mean_squared_error: 0.4516\n",
      "Epoch 00046: val_loss did not improve from 0.48939\n",
      "26/26 [==============================] - 18s 711ms/step - loss: 0.4514 - root_mean_squared_error: 0.4516 - val_loss: 0.4943 - val_root_mean_squared_error: 0.4985\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4599 - root_mean_squared_error: 0.4597\n",
      "Epoch 00047: val_loss did not improve from 0.48939\n",
      "26/26 [==============================] - 18s 709ms/step - loss: 0.4599 - root_mean_squared_error: 0.4597 - val_loss: 0.4967 - val_root_mean_squared_error: 0.5008\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4516 - root_mean_squared_error: 0.4516\n",
      "Epoch 00048: val_loss did not improve from 0.48939\n",
      "26/26 [==============================] - 18s 709ms/step - loss: 0.4516 - root_mean_squared_error: 0.4516 - val_loss: 0.4970 - val_root_mean_squared_error: 0.5012\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4594 - root_mean_squared_error: 0.4594\n",
      "Epoch 00049: val_loss did not improve from 0.48939\n",
      "26/26 [==============================] - 18s 710ms/step - loss: 0.4594 - root_mean_squared_error: 0.4594 - val_loss: 0.4963 - val_root_mean_squared_error: 0.5007\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4656 - root_mean_squared_error: 0.4655\n",
      "Epoch 00050: val_loss did not improve from 0.48939\n",
      "26/26 [==============================] - 18s 711ms/step - loss: 0.4656 - root_mean_squared_error: 0.4655 - val_loss: 0.4941 - val_root_mean_squared_error: 0.4984\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4563 - root_mean_squared_error: 0.4562\n",
      "Epoch 00051: val_loss did not improve from 0.48939\n",
      "26/26 [==============================] - 18s 709ms/step - loss: 0.4563 - root_mean_squared_error: 0.4562 - val_loss: 0.4932 - val_root_mean_squared_error: 0.4974\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4544 - root_mean_squared_error: 0.4547\n",
      "Epoch 00052: val_loss did not improve from 0.48939\n",
      "26/26 [==============================] - 18s 710ms/step - loss: 0.4544 - root_mean_squared_error: 0.4547 - val_loss: 0.4923 - val_root_mean_squared_error: 0.4963\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4513 - root_mean_squared_error: 0.4510\n",
      "Epoch 00053: val_loss did not improve from 0.48939\n",
      "26/26 [==============================] - 18s 709ms/step - loss: 0.4513 - root_mean_squared_error: 0.4510 - val_loss: 0.4936 - val_root_mean_squared_error: 0.4978\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4555 - root_mean_squared_error: 0.4553\n",
      "Epoch 00054: val_loss did not improve from 0.48939\n",
      "26/26 [==============================] - 18s 710ms/step - loss: 0.4555 - root_mean_squared_error: 0.4553 - val_loss: 0.4989 - val_root_mean_squared_error: 0.5035\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4527 - root_mean_squared_error: 0.4523\n",
      "Epoch 00055: val_loss did not improve from 0.48939\n",
      "26/26 [==============================] - 18s 710ms/step - loss: 0.4527 - root_mean_squared_error: 0.4523 - val_loss: 0.4921 - val_root_mean_squared_error: 0.4965\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4571 - root_mean_squared_error: 0.4572\n",
      "Epoch 00056: val_loss did not improve from 0.48939\n",
      "26/26 [==============================] - 18s 709ms/step - loss: 0.4571 - root_mean_squared_error: 0.4572 - val_loss: 0.4917 - val_root_mean_squared_error: 0.4959\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4530 - root_mean_squared_error: 0.4524\n",
      "Epoch 00057: val_loss did not improve from 0.48939\n",
      "26/26 [==============================] - 18s 709ms/step - loss: 0.4530 - root_mean_squared_error: 0.4524 - val_loss: 0.4914 - val_root_mean_squared_error: 0.4955\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4526 - root_mean_squared_error: 0.4529\n",
      "Epoch 00058: val_loss did not improve from 0.48939\n",
      "26/26 [==============================] - 18s 709ms/step - loss: 0.4526 - root_mean_squared_error: 0.4529 - val_loss: 0.4916 - val_root_mean_squared_error: 0.4956\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4507 - root_mean_squared_error: 0.4504\n",
      "Epoch 00059: val_loss did not improve from 0.48939\n",
      "26/26 [==============================] - 18s 709ms/step - loss: 0.4507 - root_mean_squared_error: 0.4504 - val_loss: 0.4925 - val_root_mean_squared_error: 0.4968\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4483 - root_mean_squared_error: 0.4486\n",
      "Epoch 00060: val_loss did not improve from 0.48939\n",
      "26/26 [==============================] - 18s 710ms/step - loss: 0.4483 - root_mean_squared_error: 0.4486 - val_loss: 0.4917 - val_root_mean_squared_error: 0.4958\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(loss='kld', optimizer=sgd, metrics=['accuracy'])\n",
    "# # model.compile(loss=euclidean_distance_loss, optimizer=sgd, metrics=['accuracy'])\n",
    "# root_mean_squared_error = root_mean_squared_error\n",
    "model.compile(optimizer=sgd, loss=root_mean_squared_error, metrics=root_mean_squared_error)\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='min')\n",
    "filepath = \"{epoch:02d}-{val_loss:.2f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(X_train, y_train, callbacks=[earlyStopping, checkpoint],\n",
    "            batch_size=128,\n",
    "            epochs=100,\n",
    "            verbose=1,\n",
    "            validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1416,
     "status": "ok",
     "timestamp": 1586440480610,
     "user": {
      "displayName": "Son Nguyen Trung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIjDYO028a7pzOM7YCOrcF0wUZoyGg-WZY7mtZ=s64",
      "userId": "15431692547784691678"
     },
     "user_tz": -420
    },
    "id": "S6bWyJINVHsf",
    "outputId": "7e2c3c8d-46c3-4e73-ba73-7f4078b71bf2"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['validation','training'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 302,
     "status": "ok",
     "timestamp": 1586426420697,
     "user": {
      "displayName": "Son Nguyen Trung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIjDYO028a7pzOM7YCOrcF0wUZoyGg-WZY7mtZ=s64",
      "userId": "15431692547784691678"
     },
     "user_tz": -420
    },
    "id": "UfTw9VClCa4n",
    "outputId": "15f869ea-41e4-4852-9516-f1afe802e0ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json1\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./best_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3586,
     "status": "ok",
     "timestamp": 1586446494211,
     "user": {
      "displayName": "Son Nguyen Trung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIjDYO028a7pzOM7YCOrcF0wUZoyGg-WZY7mtZ=s64",
      "userId": "15431692547784691678"
     },
     "user_tz": -420
    },
    "id": "fjuxN5N7Cizk",
    "outputId": "073a5fd7-0bd6-4a8d-dd6a-54173379cd2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.761266]\n"
     ]
    }
   ],
   "source": [
    "import imutils\n",
    "color = [(255,0,0),(0,255,255),(0,255,0),(0,100,255),(0,0,255)][::-1]\n",
    "imagepath = '/content/sample_data/th.jpg'\n",
    "face_clf = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "Model = Beau()\n",
    "Model.model.load_weights('./best_model_224.h5')\n",
    "image_name = imagepath.split('/')[-1]\n",
    "\n",
    "img = cv2.imread(imagepath)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_clf.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    fc = gray[y:y+h, x:x+w]\n",
    "\n",
    "    roi = cv2.resize(fc, (224, 224))\n",
    "    roi = roi.reshape((1,224,224,1))\n",
    "    pred = Model.model.predict(roi)[0] \n",
    "    cv2.putText(img, str(pred), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255), 2)\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),color[math.floor(pred)],2)\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(imutils.opencv2matplotlib(img))\n",
    "\n",
    "print(pred)\n",
    "# cv2.imwrite('out'+image_name,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 591,
     "status": "ok",
     "timestamp": 1586347360848,
     "user": {
      "displayName": "Son Nguyen Trung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIjDYO028a7pzOM7YCOrcF0wUZoyGg-WZY7mtZ=s64",
      "userId": "15431692547784691678"
     },
     "user_tz": -420
    },
    "id": "8TY2mCu4DI57",
    "outputId": "eda94b7a-7f44-49e2-ce34-47cbc9540a0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPCOURTJqiob"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMU2yt+Xtm4NG6JUml1QBBd",
   "collapsed_sections": [],
   "name": "beaty_evaluate.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
